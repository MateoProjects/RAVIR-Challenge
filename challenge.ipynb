{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAVIR-Challenge\n",
    "RAVIR: A Dataset and Methodology for the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and Veins in Infrared Reflectance Imaging Challenge.\n",
    "\n",
    "## Introduction\n",
    "This is an implementation to solve this challenge. This implementation is presented as a project for the subject DEEP LEARNING FOR MEDICAL IMAGE ANALYSIS (DLMIA) coursed in Universitat de Barcelona as a part of a Master Degree in Artificial Inteligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras import layers\n",
    "from sklearn import metrics\n",
    "from PIL import ImageOps\n",
    "from scipy.spatial.distance import dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_train = \"RAVIR_Dataset\\\\train\\\\training_images\"\n",
    "target_dir_train = \"RAVIR_Dataset\\\\train\\\\training_masks\"\n",
    "input_dir_train_da = \"RAVIR_Dataset_DA\\\\training_images\"\n",
    "target_dir_train_da = \"RAVIR_Dataset_DA\\\\training_masks\"\n",
    "input_dir_test = \"\"\n",
    "target_dir_test = \"\"\n",
    "img_size = (256, 256)\n",
    "def get_paths(input_dir, target_dir):\n",
    "    input_img_paths = sorted(\n",
    "      [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "      ]\n",
    "    )\n",
    "    target_img_paths = sorted(\n",
    "      [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "      ]\n",
    "    )\n",
    "    return input_img_paths, target_img_paths\n",
    "\n",
    "DATA_AUGMENTATION = True\n",
    "VALIDATION = False\n",
    "paths_train, paths_target = get_paths(input_dir_train, target_dir_train)\n",
    "#paths_test , path_target_test = get_paths(input_dir_test, target_dir_test)\n",
    "paths_train_da , paths_target_da = get_paths(input_dir_train_da, target_dir_train_da)\n",
    "paths_train_val, paths_target_val = [],[]\n",
    "\n",
    "if DATA_AUGMENTATION:\n",
    "  paths_train += paths_train_da\n",
    "  paths_target += paths_target_da\n",
    "else:\n",
    "  del paths_train_da, paths_target_da\n",
    "\n",
    "if VALIDATION:\n",
    "  split = int(len(paths_train)*0.8)\n",
    "  paths_train_val = paths_train[split:]\n",
    "  paths_train = paths_train[:split]\n",
    "  paths_target_val = paths_target[split:]\n",
    "  paths_target = paths_target[:split]\n",
    "\n",
    "print(\"Total images:\", len(paths_train))\n",
    "print(\"Total target images:\", len(paths_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            img = np.array(img)\n",
    "            img[img==255] = 2\n",
    "            img[img==128] = 1\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "        return x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Model used for this challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATORS AND CONSTANTS TO TRAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 8\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = (512,512)\n",
    "lr = 0.001\n",
    "optimizerA = keras.optimizers.Adam(learning_rate=lr)\n",
    "optimizerRMSPROP = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "\n",
    "\n",
    "train_generator = DataGenerator(BATCHSIZE, IMAGE_SIZE, paths_train, paths_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(IMAGE_SIZE, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizerA, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\" ])\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"ravir_challenge.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "]\n",
    "if VALIDATION:\n",
    "    val_generator = DataGenerator(BATCHSIZE, IMAGE_SIZE, paths_train_val, paths_target_val)\n",
    "    mdl_hist = model.fit(train_generator, epochs=EPOCHS, validation_data=val_generator, callbacks=callbacks)\n",
    "else:\n",
    "    mdl_hist = model.fit(train_generator, epochs=EPOCHS, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mdl_hist.history['loss'], label='train loss')\n",
    "if VALIDATION:\n",
    "    plt.plot(mdl_hist.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"unet_data_epochs_\" + str(EPOCHS) + \"_batchSize_\"+ str(BATCHSIZE) + '_LossVal_loss')\n",
    "plt.show()\n",
    "# plot the accuracy\n",
    "plt.plot(mdl_hist.history['accuracy'], label='train acc')\n",
    "if VALIDATION:\n",
    "    plt.plot(mdl_hist.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig(\"unet_data_epochs_\" +str(EPOCHS)+\"_batchSize_\"+ str(BATCHSIZE)+'_AccVal_acc')\n",
    "#save model to disk\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizerA, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\" ])\n",
    "model.load_weights('ravir_challenge_bo_da.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = model.evaluate(train_generator, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)\n",
    "val_preds = model.predict(train_generator)\n",
    "\n",
    "def mask_to_image(preds, i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = keras.preprocessing.image.array_to_img(mask)\n",
    "    return img\n",
    "\n",
    "\n",
    "import numpy.ma as ma\n",
    "\n",
    "# Display results for validation image #10\n",
    "inds = [0,2,4,8]\n",
    "\n",
    "# Create figure and plot\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "nrows = len(inds)\n",
    "ncols = 3\n",
    "\n",
    "for row, i in enumerate(inds):\n",
    "    base_ind = row*ncols\n",
    "\n",
    "    # Add the original image subplot at the 1st position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+1)\n",
    "    image = plt.imread(paths_train[i])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "\n",
    "    # Add the original target subplot at the 2nd position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+2)\n",
    "    target = plt.imread(paths_target[i])\n",
    "    plt.imshow(target, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Target\")\n",
    "\n",
    "    # Add the predicted target subplot at the 3rd position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+3)\n",
    "    pred = mask_to_image(val_preds, i)\n",
    "    plt.imshow(pred, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing metrics Sensitivity, Specificity, Accuracy, Jaccard and Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def get_values(y_true, y_pred):\n",
    "    # True Positives\n",
    "    tp = np.sum(np.logical_and(y_pred == 1, y_true == 1))\n",
    "    # True Negatives\n",
    "    tn = np.sum(np.logical_and(y_pred == 0, y_true == 0))\n",
    "    # False Positives\n",
    "    fp = np.sum(np.logical_and(y_pred == 1, y_true == 0))\n",
    "    # False Negatives\n",
    "    fn = np.sum(np.logical_and(y_pred == 0, y_true == 1))\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    #return metrics.recall_score(y_true, y_pred, zero_division=0,average='micro')\n",
    "    tn, fp, fn, tp = get_values(y_true, y_pred) \n",
    "    res = (tp)/(tp+fn)\n",
    "    return res\n",
    "\n",
    "def specificity(y_true , y_pred, epsilon=1e-20):\n",
    "    tn, fp, _, _ = get_values(y_true, y_pred)\n",
    "    res = (tn)/(tn+fp+epsilon)\n",
    "    return res\n",
    "\n",
    "def accuracy(y_true, y_pred, epsilon=1e-20):\n",
    "    tn, fp, fn, tp = get_values(y_true, y_pred)\n",
    "    res = (tp+tn)/(tp+fp+tn+fn+epsilon)\n",
    "    return res\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    tn, fp, fn, tp = get_values(y_true, y_pred)\n",
    "\n",
    "    return (tp)/(tp+fp+fn)\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=1e-20):\n",
    "    _ , fp, fn, tp = get_values(y_true, y_pred)\n",
    "    res = (2*tp)/(2*tp+fp+fn+epsilon)\n",
    "    return res\n",
    "if VALIDATION:\n",
    "  test_generator = val_generator\n",
    "else:\n",
    "  test_generator = DataGenerator(1, IMAGE_SIZE, paths_train, paths_target)\n",
    "\n",
    "values = []\n",
    "results = model.predict(test_generator)\n",
    "print(\"############################################\")\n",
    "sensitivity_val = 0\n",
    "accuracy_val = 0\n",
    "specificity_val = 0\n",
    "jaccard_val = 0\n",
    "dice_val = 0\n",
    "\n",
    "\n",
    "for i in range(len(results)):\n",
    "    img = results[i]\n",
    "    img_true = np.array(load_img(paths_target_val[i],target_size=(512,512),color_mode=\"grayscale\"))\n",
    "    img_true = img_true/255\n",
    "    mask = np.argmax(img, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = keras.preprocessing.image.array_to_img(mask)\n",
    "    img = np.array(img)\n",
    "    img = np.around(img)\n",
    "    img = img/255\n",
    "    #print(img_true)\n",
    "    sensitivity_val += sensitivity(img_true, img)\n",
    "    specificity_val += specificity(img_true, img)\n",
    "    accuracy_val += accuracy(img_true, img)\n",
    "    jaccard_val += jaccard(img_true,img)\n",
    "    dice_val += dice_coef(img_true, img)\n",
    "values.append([sensitivity_val/len(results), specificity_val/len(results), accuracy_val/len(results), jaccard_val/len(results), dice_val/len(results)])\n",
    "print(\"Sensitivity:\", sensitivity_val/len(results))\n",
    "print(\"Specificity:\", specificity_val/len(results))\n",
    "print(\"Accuracy:\", accuracy_val/len(results))\n",
    "print(\"jaccard:\", jaccard_val/len(results))\n",
    "print(\"dice_val:\", dice_val/len(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24a01623d0a6e38fe36673dd3da609f011920013363540fd2207b39af661eb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
