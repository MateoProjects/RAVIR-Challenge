{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAVIR-Challenge\n",
    "RAVIR: A Dataset and Methodology for the Semantic Segmentation and Quantitative Analysis of Retinal Arteries and Veins in Infrared Reflectance Imaging Challenge.\n",
    "\n",
    "## Introduction\n",
    "This is an implementation to solve this challenge. This implementation is presented as a project for the subject DEEP LEARNING FOR MEDICAL IMAGE ANALYSIS (DLMIA) coursed in Universitat de Barcelona as a part of a Master Degree in Artificial Inteligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from PIL import ImageOps\n",
    "from scipy.spatial.distance import dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_train = \"\"\n",
    "target_dir_train = \"\"\n",
    "input_dir_test = \"\"\n",
    "target_dir_test = \"\"\n",
    "img_size = (256, 256)\n",
    "def get_paths(input_dir, target_dir):\n",
    "    input_img_paths = sorted(\n",
    "      [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "      ]\n",
    "    )\n",
    "    target_img_paths = sorted(\n",
    "      [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "      ]\n",
    "    )\n",
    "    return input_img_paths, target_img_paths\n",
    "\n",
    "paths_train, paths_target = get_paths(input_dir_train, target_dir_train)\n",
    "paths_test , path_target_test = get_paths(input_dir_test, target_dir_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "            # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "            y[j] -= 1\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Model used for this challenge is Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = get_model((256,256), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 8\n",
    "EPOCHS = 30\n",
    "lr = 0.001\n",
    "optimizerA = keras.optimizers.Adam(learning_rate=lr)\n",
    "optimizerRMSPROP = keras.optimizer.RMSprop(learning_rate=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizerA, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\" ])\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"ravir_challenge.h5\", save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=1, mode='auto', restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "mdl_hist = model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mdl_hist.history['loss'], label='train loss')\n",
    "plt.plot(mdl_hist.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"data_epochs_\" +str(EPOCHS)+\"_batchSize_\"+ str(batch_size)+'_LossVal_loss')\n",
    "plt.show()\n",
    "# plot the accuracy\n",
    "plt.plot(mdl_hist.history['accuracy'], label='train acc')\n",
    "plt.plot(mdl_hist.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig(\"data_epochs_\" +str(EPOCHS)+\"_batchSize_\"+ str(batch_size)+'_AccVal_acc')\n",
    "#save model to disk\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_generator, batch_size=8)\n",
    "print(\"test loss, test acc:\", results)\n",
    "val_preds = model.predict(test_generator)\n",
    "\n",
    "def mask_to_image(preds, i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = keras.preprocessing.image.array_to_img(mask)\n",
    "    return img\n",
    "\n",
    "\n",
    "import numpy.ma as ma\n",
    "\n",
    "# Display results for validation image #10\n",
    "inds = [0,2,4,8,16]\n",
    "\n",
    "# Create figure and plot\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "nrows = len(inds)\n",
    "ncols = 3\n",
    "\n",
    "for row, i in enumerate(inds):\n",
    "    base_ind = row*ncols\n",
    "\n",
    "    # Add the original image subplot at the 1st position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+1)\n",
    "    image = plt.imread(input_test_paths[i])\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original Image\")\n",
    "\n",
    "    # Add the original target subplot at the 2nd position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+2)\n",
    "    target = plt.imread(target_test_paths[i])\n",
    "    plt.imshow(target, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Target\")\n",
    "\n",
    "    # Add the predicted target subplot at the 3rd position\n",
    "    fig.add_subplot(nrows, ncols, base_ind+3)\n",
    "    pred = mask_to_image(val_preds, i)\n",
    "    plt.imshow(pred, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24a01623d0a6e38fe36673dd3da609f011920013363540fd2207b39af661eb97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
